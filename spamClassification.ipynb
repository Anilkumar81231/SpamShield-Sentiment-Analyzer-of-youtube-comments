{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ff064e3",
   "metadata": {},
   "source": [
    "# Spam Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0f3bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   #data manupilation and analysis \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  #raw data to matrix of term frequency-inverse doc frequency\n",
    "from sklearn.model_selection import train_test_split   #split into train and test sets\n",
    "from sklearn.naive_bayes import MultinomialNB   #data represented as word vector counts\n",
    "from sklearn.pipeline import Pipeline  #single obj is used for train and test\n",
    "from sklearn.metrics import accuracy_score  #to compute accuracy\n",
    "import joblib  #to save and load the model after training\n",
    "import re  #regular expression for matching str, data preprocessing\n",
    "\n",
    "# Load the dataset into dataframe\n",
    "df = pd.read_csv('dataset/spam_detection_dataset.csv', encoding='latin1')\n",
    "\n",
    "df = df['column_name'].fillna(df['column_name'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04009417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cleaning functions\n",
    "def remove_urls(text):\n",
    "    return re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "def remove_non_ascii(text):\n",
    "    # Remove non-ASCII characters\n",
    "    return ''.join(char for char in text if ord(char) < 128)\n",
    "\n",
    "def remove_digits(text):\n",
    "    # Remove numeric digits\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    # Remove special characters except whitespace\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "def normalize_case(text):\n",
    "    # Normalize text to lowercase\n",
    "    return text.lower()\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = remove_urls(text)\n",
    "    # Remove non-ASCII characters\n",
    "    text = remove_non_ascii(text)\n",
    "    # Remove numeric digits\n",
    "    text = remove_digits(text)\n",
    "    # Remove special characters except whitespace\n",
    "    text = remove_special_characters(text)\n",
    "    # Normalize case\n",
    "    text = normalize_case(text)\n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "# Apply cleaning functions to the 'comment' column\n",
    "df['comment'] = df['comment'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdf032c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X = df['comment']\n",
    "y = df['spam']  # Assuming 'spam' is the column with binary labels (1 for spam, 0 for non-spam)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f35f15a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9029503105590062\n"
     ]
    }
   ],
   "source": [
    "# Define a function to train, evaluate models, and print the classification report\n",
    "def train_and_evaluate_model(pipeline, model_name):\n",
    "    # Train the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'{model_name} Accuracy: {accuracy}')\n",
    "    \n",
    "    # Print precision, recall, and F1-score\n",
    "    print(f'{model_name} Classification Report:\\n')\n",
    "    print(classification_report(y_test, y_pred, target_names=['not spam', 'spam']))\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6154f7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spam_detection_model.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. SVM Model\n",
    "pipeline_svm = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('svc', SVC(kernel='linear'))  # SVM classifier with a linear kernel\n",
    "])\n",
    "train_and_evaluate_model(pipeline_svm, 'SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "689e296b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              comment  spam_prediction\n",
      "0                              ayas stupid overacting                0\n",
      "1                              khushis episode coming                0\n",
      "2                              popatlal randwa marega                0\n",
      "3        apne mujhe bataa ya nhi ki apki beti bhi hai                0\n",
      "4                           kya dimagggg hai popatlal                0\n",
      "5   arre oo yeh kya matlb kuch bhi family show hai...                0\n",
      "6   tarak bhai mehta anjali ben mehta are really g...                0\n",
      "7   if there were no girl there were no one in the...                0\n",
      "8               popotlal ki shadi hogi rcb jab jitegi                0\n",
      "9   son is son till wife daughter is daughter till...                0\n",
      "10                              khusi episodes coming                0\n",
      "11              i like taraak mehta ka ooltah chansma                0\n",
      "12                   polar bhai ki shaadi jald hi jai                0\n",
      "13                  loved this product will buy again                0\n",
      "14                     claim your free vacation today                1\n",
      "15             the quality of this product is amazing                0\n",
      "16         you have been selected for a special offer                1\n",
      "17                                          nice show                0\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the file\n",
    "model = joblib.load('spam_detection_model.pkl')\n",
    "\n",
    "# Create a DataFrame with dummy values\n",
    "data = {\n",
    "    'comment': [\n",
    "        'ayas stupid overacting',\n",
    "        'khushis episode coming',\n",
    "        'popatlal randwa marega',\n",
    "        'apne mujhe bataa ya nhi ki apki beti bhi hai',\n",
    "        'kya dimagggg hai popatlal',\n",
    "        'arre oo yeh kya matlb kuch bhi family show hai yaar mat dikhao rre baba aisa kuch bhi',\n",
    "        'tarak bhai mehta anjali ben mehta are really good pair',\n",
    "        'if there were no girl there were no one in the world because a girl give birth to everyone',\n",
    "        'popotlal ki shadi hogi rcb jab jitegi',\n",
    "        'son is son till wife daughter is daughter till life',\n",
    "        'khusi episodes coming',\n",
    "        'i like taraak mehta ka ooltah chansma',\n",
    "        'polar bhai ki shaadi jald hi jai',\n",
    "        'Loved this product, will buy again.',\n",
    "        'Claim your free vacation today!',\n",
    "        'The quality of this product is amazing.',\n",
    "        'You have been selected for a special offer.',\n",
    "        'nice show'\n",
    "    ]\n",
    "}\n",
    "\n",
    "new_data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Basic data cleaning on new data\n",
    "new_data['comment'] = new_data['comment'].str.lower()  # Convert to lowercase\n",
    "new_data['comment'] = new_data['comment'].str.replace(r'\\d+', '', regex=True)  # Remove numbers\n",
    "new_data['comment'] = new_data['comment'].str.replace(r'[^\\w\\s]', '', regex=True)  # Remove punctuation\n",
    "new_data['comment'] = new_data['comment'].str.strip()  # Remove whitespace\n",
    "\n",
    "# Predict using the loaded model\n",
    "new_predictions = model.predict(new_data['comment'])\n",
    "\n",
    "# Add predictions to the new data\n",
    "new_data['spam_prediction'] = new_predictions\n",
    "\n",
    "print(new_data.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b4738e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489052d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
