{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import re\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('dataset/sentiment_detection_dataset.csv', encoding='latin1')\n",
    "df = df.dropna()\n",
    "\n",
    "# Map the label column values\n",
    "label_mapping = {\n",
    "    'negative': 0,\n",
    "    'neutral': 1,\n",
    "    'positive': 2\n",
    "}\n",
    "df['label'] = df['label'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cleaning functions\n",
    "def remove_urls(text):\n",
    "    return re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "def remove_non_ascii(text):\n",
    "    # Remove non-ASCII characters\n",
    "    return ''.join(char for char in text if ord(char) < 128)\n",
    "\n",
    "def remove_digits(text):\n",
    "    # Remove numeric digits\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    # Remove special characters except whitespace\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "def normalize_case(text):\n",
    "    # Normalize text to lowercase\n",
    "    return text.lower()\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = remove_urls(text)\n",
    "    # Remove non-ASCII characters\n",
    "    text = remove_non_ascii(text)\n",
    "    # Remove numeric digits\n",
    "    text = remove_digits(text)\n",
    "    # Remove special characters except whitespace\n",
    "    text = remove_special_characters(text)\n",
    "    # Normalize case\n",
    "    text = normalize_case(text)\n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "# Apply cleaning functions to the 'comment' column\n",
    "df['comment'] = df['comment'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X = df['comment']\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train, evaluate models and print the classification report\n",
    "def train_and_evaluate_model(pipeline, model_name):\n",
    "    # Train the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'{model_name} Accuracy: {accuracy}')\n",
    "    \n",
    "    # Print precision, recall, and F1-score\n",
    "    print(f'{model_name} Classification Report:\\n')\n",
    "    print(classification_report(y_test, y_pred, target_names=['negative', 'neutral', 'positive']))\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.6940805434255216\n",
      "SVM Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.57      0.64      2356\n",
      "     neutral       0.64      0.75      0.69      3343\n",
      "    positive       0.77      0.73      0.75      2545\n",
      "\n",
      "    accuracy                           0.69      8244\n",
      "   macro avg       0.71      0.69      0.69      8244\n",
      "weighted avg       0.70      0.69      0.69      8244\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 1. SVM Model\n",
    "pipeline_svm = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('svc', SVC(kernel='linear'))  # SVM classifier with a linear kernel\n",
    "])\n",
    "train_and_evaluate_model(pipeline_svm, 'SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6754002911208151\n",
      "Logistic Regression Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.52      0.61      2356\n",
      "     neutral       0.61      0.77      0.68      3343\n",
      "    positive       0.77      0.69      0.73      2545\n",
      "\n",
      "    accuracy                           0.68      8244\n",
      "   macro avg       0.70      0.66      0.67      8244\n",
      "weighted avg       0.69      0.68      0.67      8244\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 2. Logistic Regression Model\n",
    "pipeline_lr = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('lr', LogisticRegression(max_iter=1000,C=0.5))  # Logistic Regression\n",
    "])\n",
    "train_and_evaluate_model(pipeline_lr, 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.435710819990296\n",
      "Random Forest Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.01      0.02      2356\n",
      "     neutral       0.42      0.99      0.59      3343\n",
      "    positive       0.88      0.10      0.18      2545\n",
      "\n",
      "    accuracy                           0.44      8244\n",
      "   macro avg       0.70      0.37      0.26      8244\n",
      "weighted avg       0.67      0.44      0.30      8244\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 3. Random Forest Model\n",
    "pipeline_rf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100,max_depth=10))  # Random Forest Classifier\n",
    "])\n",
    "train_and_evaluate_model(pipeline_rf, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.6259097525473072\n",
      "Naive Bayes Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.41      0.53      2356\n",
      "     neutral       0.55      0.80      0.65      3343\n",
      "    positive       0.74      0.60      0.66      2545\n",
      "\n",
      "    accuracy                           0.63      8244\n",
      "   macro avg       0.68      0.60      0.61      8244\n",
      "weighted avg       0.66      0.63      0.62      8244\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 4. Naive Bayes Model\n",
    "pipeline_nb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('nb', MultinomialNB())  # Naive Bayes Classifier\n",
    "])\n",
    "train_and_evaluate_model(pipeline_nb, 'Naive Bayes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
